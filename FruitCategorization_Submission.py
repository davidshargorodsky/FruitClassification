# -*- coding: utf-8 -*-
"""BestSub_996.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1778a5t0PgdRDMCsPkq_VOtnDgSj_t0_p

### 1) Loading in Data
"""

import pandas as pd
import numpy as np
import io

from google.colab import drive
drive.mount('/content/gdrive')

import pickle

# Getting back the objects:
with open('/content/gdrive/My Drive/Colab Notebooks/Final Project/fruit_data.pkl', 'rb') as f:  
    x_train, y_train, x_test = pickle.load(f)

train_images = np.ndarray(shape=(len(x_train),105,105,3))
test_images = np.ndarray(shape=(len(x_test),105,105,3))

for i in range(len(x_train)):
  train_images[i] = x_train[i,23:128,23:128,:]

for i in range(len(x_test)):
  test_images[i] = x_test[i,23:128,23:128,:]

from tensorflow.keras.utils import to_categorical
train_images = train_images.astype('float32') / 255
test_images = test_images.astype('float32') / 255

train_labels = to_categorical(y_train)

"""### 2) Exploring the Dataset"""

import matplotlib.pyplot as plt
plt.imshow(train_images[11800,:,:,:])

import matplotlib.pyplot as plt
plt.imshow(test[2,:,:,:])

"""### 3) Model Building

"""

from tensorflow.keras.applications import InceptionResNetV2

conv_base = InceptionResNetV2(weights='imagenet',
                  include_top=False,
                  input_shape=(105,105,3))

conv_base.summary()

set_trainable = False
for layer in conv_base.layers:
    if layer.name == 'block35_9_conv':
        set_trainable = True
    if set_trainable:
        layer.trainable = True
    else:
        layer.trainable = False

from keras import layers
from keras import models
from keras import regularizers

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dropout(0.4))
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dropout(0.4))
model.add(layers.Dense(19, activation='softmax'))

model.summary()

from tensorflow.keras import metrics as metrics
from tensorflow.keras import optimizers
opt = optimizers.Nadam(learning_rate=1e-3)

model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=[metrics.CategoricalAccuracy()])

history=model.fit(train_images, train_labels, epochs=80, validation_split=0.18, batch_size=818)

import matplotlib.pyplot as plt

acc = history.history['categorical_accuracy']
val_acc = history.history['val_categorical_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, '--g', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, '--g', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

"""### 4) Making Predictions"""

model.save('/content/gdrive/My Drive/Colab Notebooks/Final Project/submissionDS108_Final.h5')

from keras import models
model = models.load_model('/content/gdrive/My Drive/Colab Notebooks/Final Project/submissionDS108_Final.h5')

import numpy as np
import pandas as pd
pred = model.predict(test_images)
mx = np.argmax(pred, axis=1)
out = pd.DataFrame({'Class': mx}, index=pd.RangeIndex(start=1, stop=10101, name='ID'))
out.to_csv("/content/gdrive/My Drive/Colab Notebooks/Final Project/submissionDS108_Final.csv")